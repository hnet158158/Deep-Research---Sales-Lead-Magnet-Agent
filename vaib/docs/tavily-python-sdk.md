# Tavily Python SDK Documentation

## Quickstart

Integrate Tavily's powerful APIs natively in your Python apps.

### Installation

```bash
pip install tavily-python
```

### Usage

With Tavily's Python SDK, you can search the web in only 4 lines of code:

```python
from tavily import TavilyClient

tavily_client = TavilyClient(api_key="tvly-YOUR_API_KEY")
response = tavily_client.search("Who is Leo Messi?")
print(response)
```

You can also easily extract content from URLs:

```python
from tavily import TavilyClient

tavily_client = TavilyClient(api_key="tvly-YOUR_API_KEY")
response = tavily_client.extract("https://en.wikipedia.org/wiki/Lionel_Messi")
print(response)
```

Tavily also allows you to perform a smart crawl starting at a given URL:

```python
from tavily import TavilyClient

tavily_client = TavilyClient(api_key="tvly-YOUR_API_KEY")
response = tavily_client.crawl("https://docs.tavily.com", instructions="Find all pages on the Python SDK")
print(response)
```

## API Methods

### Tavily Search

The `search` function lets you harness the full power of Tavily Search.

#### Parameters

| Parameter | Type | Description | Default |
| --- | --- | --- | --- |
| `query` **(required)** | `str` | The query to run a search on. | — |
| `auto_parameters` | `bool` | When `auto_parameters` is enabled, Tavily automatically configures search parameters based on your query's content and intent. | `"false"` |
| `search_depth` | `str` | The depth of the search. It can be `"basic"` or `"advanced"`. | `"basic"` |
| `topic` | `str` | The category of the search. Supported values are `"general"`, `"news"` and `"finance"`. | `"general"` |
| `time_range` | `str` | The time range back from the current date. Accepted values include `"day"`, `"week"`, `"month"`, `"year"` or shorthand values `"d"`, `"w"`, `"m"`, `"y"`. | — |
| `start_date` | `str` | Will return all results after the specified start date. Required to be written in format YYYY-MM-DD | — |
| `end_date` | `str` | Will return all results before the specified end date. Required to be written in format YYYY-MM-DD | — |
| `max_results` | `int` | The maximum number of search results to return. It must be between `0` and `20`. | `5` |
| `chunks_per_source` | `int` | Chunks are short content snippets (maximum 500 characters each) pulled directly from the source. | `3` |
| `include_images` | `bool` | Include a list of query-related images in the response. | `False` |
| `include_image_descriptions` | `bool` | Include a list of query-related images and their descriptions in the response. | `False` |
| `include_answer` | `bool` or `str` | Include an answer to the query generated by an LLM based on search results. | `False` |
| `include_raw_content` | `bool` or `str` | Include cleaned and parsed HTML content of each search result. | `False` |
| `include_domains` | `list[str]` | A list of domains to specifically include in the search results. Maximum 300 domains. | `[]` |
| `exclude_domains` | `list[str]` | A list of domains to specifically exclude from the search results. Maximum 150 domains. | `[]` |
| `country` | `str` | Boost search results from a specific country. | — |
| `timeout` | `float` | A timeout to be used in requests to the Tavily API. | `60` |
| `include_favicon` | `bool` | Whether to include favicon URL for each result. | `False` |
| `include_usage` | `bool` | Whether to include credit usage information in the response. | `False` |

#### Response Format

| Key | Type | Description |
| --- | --- | --- |
| `results` | `list[Result]` | A list of sorted search results ranked by relevance. |
| `query` | `str` | Your search query. |
| `response_time` | `float` | Your search result response time. |
| `answer` (optional) | `str` | The answer to your search query, generated by an LLM based on Tavily's search results. |
| `images` (optional) | `list[str]` or `list[ImageResult]` | This is only available if `include_images` is set to `True`. |
| `request_id` | `str` | A unique request identifier you can share with customer support. |

#### Result Format

| Key | Type | Description |
| --- | --- | --- |
| `title` | `str` | The title of the search result. |
| `url` | `str` | The URL of the search result. |
| `content` | `str` | The most query-related content from the scraped URL. |
| `score` | `float` | The relevance score of the search result. |
| `raw_content` (optional) | `str` | The parsed and cleaned HTML content of the site. |
| `published_date` (optional) | `str` | The publication date of the source. |
| `favicon` (optional) | `str` | The favicon URL for the search result. |

### Tavily Extract

The `extract` function allows you to easily retrieve web content with Tavily Extract.

#### Parameters

| Parameter | Type | Description | Default |
| --- | --- | --- | --- |
| `urls` **(required)** | `str` or `list[str]` | The URL (or URLs) you want to extract. If a list is provided, it must not contain more than 20 URLs. | — |
| `include_images` | `bool` | Include a list of images extracted from the URLs in the response. | `False` |
| `extract_depth` | `str` | The depth of the extraction process. `"basic"` or `"advanced"`. | `"basic"` |
| `format` | `str` | The format of the extracted web page content. `"markdown"` or `"text"`. | `"markdown"` |
| `timeout` | `float` | A timeout to be used in requests to the Tavily API. | `None` |
| `include_favicon` | `bool` | Whether to include favicon URL for each result. | `False` |
| `include_usage` | `bool` | Whether to include credit usage information in the response. | `False` |
| `query` | `str` | User intent for reranking extracted content. | `None` |
| `chunks_per_source` | `int` | Chunks are short content snippets (maximum 500 characters each) pulled directly from the source. | `3` |

#### Response Format

| Key | Type | Description |
| --- | --- | --- |
| `results` | `list[SuccessfulResult]` | A list of extracted content. |
| `failed_results` | `list[FailedResult]` | A list of URLs that could not be processed. |
| `response_time` | `float` | The search result response time. |
| `request_id` | `str` | A unique request identifier. |

#### Successful Result Format

| Key | Type | Description |
| --- | --- | --- |
| `url` | `str` | The URL of the webpage. |
| `raw_content` | `str` | The raw content extracted. |
| `images` (optional) | `list[str]` | This is only available if `include_images` is set to `True`. |
| `favicon` (optional) | `str` | The favicon URL for the search result. |

#### Failed Result Format

| Key | Type | Description |
| --- | --- | --- |
| `url` | `str` | The URL that failed. |
| `error` | `str` | An error message describing why it could not be processed. |

### Tavily Crawl

The `crawl` function allows you to intelligently traverse websites and extract content.

#### Parameters

| Parameter | Type | Description | Default |
| --- | --- | --- | --- |
| `url` **(required)** | `str` | The root URL to begin to crawl. | — |
| `max_depth` | `int` | Max depth of the crawl. | `1` |
| `max_breadth` | `int` | Max number of links to follow **per level** of the tree. | `20` |
| `limit` | `int` | Total number of links the crawler will process before stopping. | `50` |
| `instructions` | `str` | Natural language instructions for the crawler. | — |
| `select_paths` | `list[str]` | Regex patterns to select only URLs with specific path patterns. | `None` |
| `select_domains` | `list[str]` | Regex patterns to select crawling to specific domains or subdomains. | `None` |
| `exclude_paths` | `list[str]` | Regex patterns to exclude URLs with specific path patterns. | `None` |
| `exclude_domains` | `list[str]` | Regex patterns to exclude specific domains or subdomains from the crawling. | `None` |
| `allow_external` | `bool` | Whether to allow following links that go to external domains. | `True` |
| `include_images` | `bool` | Whether to extract image URLs from crawled pages. | `False` |
| `extract_depth` | `str` | Advanced extraction retrieves more data. | `"basic"` |
| `format` | `str` | The format of the extracted web page content. | `"markdown"` |
| `include_favicon` | `bool` | Whether to include favicon URL for each result. | `False` |
| `timeout` | `float` | Maximum time in seconds to wait for the crawl operation. | `150` |
| `include_usage` | `bool` | Whether to include credit usage information in the response. | `False` |
| `chunks_per_source` | `int` | Chunks are short content snippets (maximum 500 characters each). | `3` |

#### Response Format

| Key | Type | Description |
| --- | --- | --- |
| `base_url` | `str` | The URL you started to crawl from. |
| `results` | `list[Result]` | A list of crawled pages. |
| `response_time` | `float` | The crawl result response time. |
| `request_id` | `str` | A unique request identifier. |

#### Result Format

| Key | Type | Description |
| --- | --- | --- |
| `url` | `str` | The URL of the webpage. |
| `raw_content` | `str` | The raw content extracted. |
| `images` | `list[str]` | Image URLs extracted from the page. |
| `favicon` (optional) | `str` | The favicon URL for the search result. |

### Tavily Map

The `map` function allows you to obtain a sitemap starting from a base URL.

#### Parameters

| Parameter | Type | Description | Default |
| --- | --- | --- | --- |
| `url` **(required)** | `str` | The root URL to begin to mapping. | — |
| `max_depth` | `int` | Max depth of the mapping. | `1` |
| `max_breadth` | `int` | Max number of links to follow **per level** of the tree. | `20` |
| `limit` | `int` | Total number of links the crawler will process before stopping. | `50` |
| `query` | `str` | Natural language instructions for the crawler. | — |
| `select_paths` | `list[str]` | Regex patterns to select only URLs with specific path patterns. | `None` |
| `select_domains` | `list[str]` | Regex patterns to select crawling to specific domains or subdomains. | `None` |
| `exclude_paths` | `list[str]` | Regex patterns to exclude URLs with specific path patterns. | `None` |
| `exclude_domains` | `list[str]` | Regex patterns to exclude specific domains or subdomains from the mapping. | `None` |
| `allow_external` | `bool` | Whether to allow following links that go to external domains. | `False` |
| `timeout` | `float` | Maximum time in seconds to wait for the map operation. | `150` |
| `include_usage` | `bool` | Whether to include credit usage information in the response. | `False` |

#### Response Format

| Key | Type | Description |
| --- | --- | --- |
| `base_url` | `str` | The URL you started to map from. |
| `results` | `list[str]` | A list of URLs that were discovered during the mapping. |
| `response_time` | `float` | The mapping result response time. |
| `request_id` | `str` | A unique request identifier. |

## Client Configuration

### Instantiating a Client

To interact with Tavily in Python, you must instantiate a client with your API key. We provide both a synchronous and an asynchronous client class.

#### Synchronous Client

```python
from tavily import TavilyClient

client = TavilyClient("tvly-YOUR_API_KEY")
```

#### Asynchronous Client

```python
from tavily import AsyncTavilyClient

client = AsyncTavilyClient("tvly-YOUR_API_KEY")
```

#### Project Tracking

You can attach a Project ID to your client to organize and track API usage by project.

```python
from tavily import TavilyClient

client = TavilyClient("tvly-YOUR_API_KEY", project_id="your-project-id")
```

Alternatively, you can set the `TAVILY_PROJECT` environment variable:

```python
import os

os.environ["TAVILY_PROJECT"] = "your-project-id"
client = TavilyClient("tvly-YOUR_API_KEY")
```

#### Proxies

If you would like to specify a proxy to be used when making requests, you can do so by passing in a proxy parameter on client instantiation.

```python
from tavily import TavilyClient

proxies = {
    "http": "http://your-proxy.com",
    "https": "https://your-proxy.com",
}

client = TavilyClient("tvly-YOUR_API_KEY", proxies=proxies)
```

Alternatively, you can specify which proxies to use by setting `TAVILY_HTTP_PROXY` and `TAVILY_HTTPS_PROXY` variables in your environment file.
